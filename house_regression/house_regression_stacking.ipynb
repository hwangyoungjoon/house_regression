{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.linear_model import Ridge, LassoCV,LassoLarsCV, ElasticNet\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import skew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv(\"./train.csv\") # read train data\n",
    "test = pd.read_csv(\"./test.csv\") # read test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error(real_value, prediction):\n",
    "    return mean_squared_error(real_value,prediction)**0.5\n",
    "\n",
    "RMSE = make_scorer(error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ensemble(object):\n",
    "    def __init__(self,n_folds,stacker,base_models):\n",
    "        self.n_folds=n_folds\n",
    "        self.stacker=stacker\n",
    "        self.base_models=base_models\n",
    "        \n",
    "    def fit_perdict(self,train,test,ytr):\n",
    "        X=train.values\n",
    "        y=ytr.values\n",
    "        T=test.values\n",
    "        \n",
    "        folds=list(KFold(len(y)),n_folds=self.n_folds,shuffle=True,random_state=0)\n",
    "        s_train=np.zeros((X.shape[0],len(self.base_models)))\n",
    "        s_test=np.zeros(T.shape[0],len(self.base_models))\n",
    "        \n",
    "        for i, ref in enumerate(base_models):\n",
    "            print(\"fittig the base model....\")\n",
    "            \n",
    "            s_test_i=np.zeros(T.shape[0],len(folds))\n",
    "            for j ,(train_idx,test_idx) in enumerate(folds):\n",
    "                x_train=x[train_idx]\n",
    "                y_train=y[train_idx]\n",
    "                x_holdout=x[test_idx]\n",
    "                reg.fit(x_train,y_train)\n",
    "                y_pred=reg.predict(x_holdout[:])\n",
    "                s_train[test_idx,i]=y_pred\n",
    "                s_test_i[:,j]=reg.predict(T)[:]\n",
    "            s_test[:,i]=s_test_i.mean(1)\n",
    "            \n",
    "            \n",
    "        printing(\"stacking base models....\")\n",
    "        \n",
    "        param_grid={\n",
    "            \n",
    "          'alpha': [1e-3,5e-3,1e-2,5e-2,1e-1,0.2,0.3,0.4,0.5,0.8,1e0,3,5,7,1e1],\n",
    "            \n",
    "        }\n",
    "        \n",
    "        grid=GridSearchCV(estimator=self.stacker, param_grid=parma_grid, n_jobs=1,cv=5,scoring=RMSE)\n",
    "        gird.fit(s_train,y)\n",
    "        \n",
    "        try:\n",
    "            print('Param grid:')\n",
    "            print(param_grid)\n",
    "            print('Best Params:')\n",
    "            print(grid.best_params_)\n",
    "            print('Best CV Score:')\n",
    "            print(-grid.best_score_)\n",
    "            print('Best estimator:')\n",
    "            print(grid.best_estimator_)\n",
    "            print(message)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        y_pred = grid.predict(S_test)[:]\n",
    "        return y_pred, -grid.best_score_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_models=[\n",
    "    RandomForestRegressor(\n",
    "    n_jobs=1, random_state=0,\n",
    "    n_estimators=500, max_features=14\n",
    "    \n",
    "    \n",
    "    ),\n",
    "    \n",
    "     RandomForestRegressor(\n",
    "    n_jobs=1, random_state=0,\n",
    "    n_estimators=500, max_features=20,\n",
    "    max_depth=7\n",
    "    \n",
    "    ),\n",
    "    \n",
    "    \n",
    "    ExtraTreesRegressor(\n",
    "    n_jobs=1, random_state=0,\n",
    "        n_estimators=500, max_features=15\n",
    "    \n",
    "    \n",
    "    \n",
    "    )\n",
    "    ,\n",
    "    \n",
    "    ExtraTreesRegressor(\n",
    "    n_jobs=1, random_state=0,\n",
    "        n_estimators=500, max_features=20\n",
    "    \n",
    "    \n",
    "    \n",
    "    )\n",
    "    ,\n",
    "    \n",
    "    GradientBoostingRegressor(\n",
    "    \n",
    "    random_state=0, \n",
    "        n_estimators=500, max_features=10, max_depth=6,\n",
    "        learning_rate=0.05, subsample=0.8\n",
    "    \n",
    "    \n",
    "    ),\n",
    "    \n",
    "    GradientBoostingRegressor(\n",
    "    \n",
    "    random_state=0, \n",
    "        n_estimators=500, max_features=15, max_depth=6,\n",
    "        learning_rate=0.05, subsample=0.8\n",
    "    \n",
    "    \n",
    "    )\n",
    ",\n",
    "    \n",
    "    \n",
    "    LassoCV(alphas=[1,0.1,0.001,0.0005]),\n",
    "    KNeighborsRegressor(n_neighbors=5),\n",
    "    KNeighborsRegressor(n_neighbors=10),\n",
    "    KNeighborsRegressor(n_neighbors=15),\n",
    "    KNeighborsRegressor(n_neighbors=25),\n",
    "    LassoLarsCV(),\n",
    "    ElasticNet(),\n",
    "    SVR()\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_preprocess(train, test):\n",
    "    outlier_idx=[   4,   11,   13,   30,   53,   66,  112,  142,  151,  153,  185,\n",
    "        199,  218,  224,  231,  238,  261,  271,  313,  318,  328,  377,\n",
    "        410,  440,  451,  454,  457,  462,  473,  488,  496,  523,  529,\n",
    "        559,  568,  581,  583,  588,  595,  607,  608,  628,  632,  666,\n",
    "        681,  688,  691,  692,  714,  738,  747,  769,  774,  803,  825,\n",
    "        864,  885,  898,  970,  990, 1046, 1065, 1142, 1169, 1181, 1182,\n",
    "       1211, 1298, 1322, 1324, 1328, 1359, 1423, 1442, 1453]\n",
    "    train.drop(train.index[outlier_idx], inplace=True)\n",
    "    \n",
    "    all_data = pd.concat([train.loc[:,'MSSubClass':'SaleCondition'], test.loc[:,'MSSubClass':'SaleCondition']])\n",
    "    \n",
    "    to_delete = ['Alley','FireplaceQu','PoolQC','Fence','MiscFeature']\n",
    "    all_data.drop(to_delete, axis=1, inplace = True)\n",
    "    \n",
    "    #log transform\n",
    "    numeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n",
    "    skewness = all_data[numeric_feats].apply(lambda x : skew(x.dropna()))\n",
    "    skewed_feats = skewness[skewness>0.75].index\n",
    "    all_data[skewed_feats] = np.log1p(all_data[skewed_feats])\n",
    "    \n",
    "    #encode categorical data\n",
    "    all_data=pd.get_dummies(all_data)\n",
    "    \n",
    "    #fillna\n",
    "    all_data = all_data.fillna(all_data.mean())\n",
    "    \n",
    "    X_train = all_data[:train.shape[0]]\n",
    "    X_test = all_data[train.shape[0]:]\n",
    "    y_train = np.log1p(train.SalePrice)\n",
    "    \n",
    "    return X_train, X_test, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train = data_preprocess(train,test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ensemble' object has no attribute 'fit_predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-f2773fdab4bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'ensemble' object has no attribute 'fit_predict'"
     ]
    }
   ],
   "source": [
    "ensem=ensemble(\n",
    "\n",
    "        n_folds=5,\n",
    "    stacker=Ridge(),\n",
    "    base_models=base_models\n",
    "\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "y_pred, score = ensem.fit_predict(x_train,x_test,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
